spring:
  application:
    name: observability-demo
  ai:
    openai:
      api-key: ${OPENAI_API_KEY:}
  docker:
    compose:
      stop:
        command: down # to stop and remove containers because qdrant needs fresh start in our demo case

management:
  endpoints:
    web:
      exposure:
        include: health,metrics, prometheus
  tracing:
    sampling:
      probability: 1.0 # The default sampling probability is set to 0.1 (10%), but for demonstration purposes, we set it to 1.0 (100%) to ensure that all traces are captured and visible in Grafana Tempo. In a production environment, you would typically use a lower sampling rate to reduce overhead and storage requirements.

opentelemetry:
  exporter:
    otlp:
      endpoint: http://localhost:4317

logging:
  pattern:
    console: "%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) - %msg%n"
  level:
    org.springframework.ai.chat.client.advisor: ERROR # required to see logs using SimpleLoggerAdvisor
